# Poem_Gen_AI

# Beyit & Åiir Creator: TÃ¼rkÃ§e Åiir Ãœretimi iÃ§in GPT-2 Fine-Tuning

Bu proje, Ã¶nceden eÄŸitilmiÅŸ bir GPT-2 modelini kullanarak TÃ¼rkÃ§e klasik ÅŸiir (Ã¶zellikle beyit ve dÃ¶rtlÃ¼k formlarÄ±nda) Ã¼retmeyi amaÃ§layan bir Generatif Yapay Zeka Ã§alÄ±ÅŸmasÄ±dÄ±r. Model, TÃ¼rk edebiyatÄ±nÄ±n inceliklerini, ÅŸiirsel yapÄ±larÄ±nÄ± ve Ã¼slup Ã¶zelliklerini yakalayarak yaratÄ±cÄ± ve sentaktik olarak doÄŸru ÅŸiirler Ã¼retmek Ã¼zere eÄŸitilmiÅŸtir.

---

## ğŸš€ Proje AmacÄ±

Bu projenin temel amacÄ±, TÃ¼rk ÅŸairlerinden derlenmiÅŸ Ã¶zel bir veri kÃ¼mesiyle Ã¶nceden eÄŸitilmiÅŸ bir GPT-2 modeline ince ayar yaparak TÃ¼rkÃ§e klasik ÅŸiirler (Ã¶zellikle beyit ve dÃ¶rtlÃ¼k formlarÄ±nda) Ã¼retmektir[cite: 1]. Model, TÃ¼rk edebi eserlerinin nÃ¼anslarÄ±nÄ±, ÅŸiirsel yapÄ±larÄ±nÄ± ve Ã¼slup Ã¶zelliklerini yakalayarak yaratÄ±cÄ± ve dilbilgisi aÃ§Ä±sÄ±ndan doÄŸru ÅŸiirler Ã¼retmek Ã¼zere eÄŸitilmiÅŸtir[cite: 2].

---

## ğŸ› ï¸ KullanÄ±lan Metodlar ve Teknolojiler

* **Model:** GPT-2 (124M parametre) [cite: 3]
* **Teknik:** HuggingFace Trainer API ile ince ayar (Fine-tuning) [cite: 3]
* **Veri Seti:** ÃœnlÃ¼ TÃ¼rk ÅŸairlerine (Ã¶rn. Yunus Emre, Fuzuli, NazÄ±m Hikmet) ait TÃ¼rkÃ§e ÅŸiirler [cite: 3]
* **Platform:** Google Colab (GPU tabanlÄ± eÄŸitim) [cite: 3]
* **KÃ¼tÃ¼phaneler:** `transformers`, `datasets`, `torch`, `sklearn`, `pandas` [cite: 3]

### Model KonfigÃ¼rasyonu:

| Parametre           | DeÄŸer                                        |
| :------------------ | :------------------------------------------- |
| Tokenizer           | Ã–zel GPT-2 tokenizer (TÃ¼rkÃ§e veri Ã¼zerinde eÄŸitilmiÅŸ) [cite: 3, 6] |
| Maksimum Dizi UzunluÄŸu | 128 token                                    |
| Epoch SayÄ±sÄ±        | 5                                            |
| Batch Boyutu        | 2                                            |
| Ã–ÄŸrenme OranÄ±       | 5e-5                                         |

---

## ğŸ§  Proje Ä°ÅŸ AkÄ±ÅŸÄ±

1.  **Veri Seti Toplama ve Ã–n Ä°ÅŸleme:**
    * Birden fazla TÃ¼rk ÅŸairinden ÅŸiirler toplandÄ± ve temizlendi[cite: 4].
    * Her ÅŸiir `\n\n` kullanÄ±larak ayrÄ±ldÄ± ve Ã¶zel karakterler kaldÄ±rÄ±ldÄ±[cite: 5].
2.  **Tokenizer EÄŸitimi:**
    * Benzersiz TÃ¼rkÃ§e karakterleri ve yapÄ±larÄ± daha iyi iÅŸlemek iÃ§in TÃ¼rkÃ§e ÅŸiir veri seti Ã¼zerinde yeni bir tokenizer eÄŸitildi[cite: 6].
3.  **Model Ä°nce AyarÄ± (Fine-Tuning):**
    * Temel GPT-2 modeli, HuggingFace Trainer kullanÄ±larak TÃ¼rkÃ§e ÅŸiirler Ã¼zerinde ince ayarlandÄ±[cite: 7].
4.  **Metin Ãœretimi:**
    * KullanÄ±cÄ± girdisine (Ã¶rn. bir kelime veya dize) gÃ¶re ÅŸiirler Ã¼retildi[cite: 8].
    * YaratÄ±cÄ± Ã¼retimi artÄ±rmak iÃ§in **Beam Search** ve **Top-k Sampling** yÃ¶ntemleri kullanÄ±ldÄ±[cite: 9].

---

## ğŸš§ KarÅŸÄ±laÅŸÄ±lan Zorluklar

* **GPU SÄ±nÄ±rlamalarÄ±:** Google Colab'Ä±n 12GB GPU'su, batch boyutunu kÃ¼Ã§Ã¼k tutmayÄ± gerekli kÄ±ldÄ±[cite: 10].
* **Tokenizer UyumluluÄŸu:** TÃ¼rkÃ§e diyakritikler (ÅŸapkalÄ± harfler) ve ÅŸiirsel hece yapÄ±larÄ±, orijinal GPT-2 tokenizer ile uyumsuzluk gÃ¶sterdi ve bu durum Ã¶zel bir tokenizer gerektirdi[cite: 11].
* **SÄ±nÄ±rlÄ± Veri Seti Boyutu:** SÄ±nÄ±rlÄ± miktardaki TÃ¼rkÃ§e ÅŸiir verisi nedeniyle aÅŸÄ±rÄ± uyum (overfitting) riski oluÅŸtu. Erken durdurma (early stopping) gibi teknikler kullanÄ±ldÄ±[cite: 12, 13].

---

## ğŸ“Š Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

AÅŸaÄŸÄ±daki tablo, projemizde ince ayar yapÄ±lmÄ±ÅŸ GPT-2 modelinin, Ã¶nceden eÄŸitilmiÅŸ genel Ä°ngilizce GPT-2 modeli ile bazÄ± Ã¶zellikleri aÃ§Ä±sÄ±ndan karÅŸÄ±laÅŸtÄ±rmasÄ±nÄ± sunmaktadÄ±r:

| Ã–zellik            | Ä°nce AyarlÄ± GPT-2 (Bu Proje) | Ã–nceden EÄŸitilmiÅŸ GPT-2 (Ä°ngilizce) |
| :----------------- | :--------------------------: | :---------------------------------: |
| TÃ¼rkÃ§e Anlama      |              â˜‘               |                  X                  |
| Åiirsel YapÄ±       |              â˜‘               |                  X                  |
| YaratÄ±cÄ± Ã‡Ä±ktÄ±     |              â˜‘               |                  â˜‘                  |
| Ã–zelleÅŸtirme MÃ¼mkÃ¼n |              â˜‘               |                  â˜‘                  |

---

## ğŸš€ Projeyi Ã‡alÄ±ÅŸtÄ±rma

Bu projeyi yerel olarak Ã§alÄ±ÅŸtÄ±rmak veya ince ayarlÄ± modeli kullanmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± takip edebilirsiniz:

### Ã–n Gereksinimler

* Python 3.x
* `pip` paket yÃ¶neticisi

### Kurulum

Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:

```bash
pip install transformers datasets torch scikit-learn pandas

 Gelecek Ã‡alÄ±ÅŸmalar
Bu projenin potansiyel geliÅŸim alanlarÄ± ÅŸunlardÄ±r:

Daha bÃ¼yÃ¼k bir GPT-2 modelinin (Ã¶rn. 345M veya 774M) kullanÄ±lmasÄ±.
Bir kafiye (rhyme) tespit modÃ¼lÃ¼nÃ¼n entegrasyonu.
KullanÄ±cÄ±larÄ±n ÅŸiir Ã¼reteci ile etkileÅŸim kurabileceÄŸi bir web veya masaÃ¼stÃ¼ GUI (grafik kullanÄ±cÄ± arayÃ¼zÃ¼) geliÅŸtirilmesi.
Daha iyi semantik derinlik iÃ§in veri setinin geniÅŸletilmesi.
âœ‰ï¸ Ä°letiÅŸim
Ad Soyad: BURAK YILDIRIM 
Ã–ÄŸrenci No: 220201047 
